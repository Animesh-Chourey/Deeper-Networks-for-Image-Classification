# -*- coding: utf-8 -*-
"""VGG_ResNet_MNIST.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1q0ACGoaUWp2welT6UI0IIvjd9MccCG76

### Mounting the drive
"""

from google.colab import drive
drive.mount('/content/drive/')

import os

if not os.path.isdir("/content/drive/My Drive/Animesh/"):
  os.mkdir("/content/drive/My Drive/Animesh/")

if not os.path.isdir("/content/drive/My Drive/Animesh/VGG_ResNet_MNIST"):
  os.mkdir("/content/drive/My Drive/Animesh/VGG_ResNet_MNIST")

!nvidia-smi

"""### Importing Packages """

# Commented out IPython magic to ensure Python compatibility.
import torch
import torchvision
import torchvision.datasets as datasets
from torchvision import transforms
from torch.utils.data import random_split
from torch import nn
import torch.nn.functional as F
import torch.optim as optim
import matplotlib.pyplot as plt
import time
import numpy as np
import itertools
import os
import random
from torch.utils.tensorboard import SummaryWriter
import json

# Load the TensorBoard notebook extension
%load_ext tensorboard

"""#### Parameters and device """

# Setting the device to GPU if available
device = 'cuda' if torch.cuda.is_available() else 'cpu'

# Setting the parameters 
batch_size = 64
epochs = 20
learning_rate = 0.0001
num_classes = 10

"""#### Loading the dataset"""

# Downloading the dataset training and test dataset

# The values used for normalize transformation are the global mean & standard deviation of the MNIST dataset
# Resizing the test and train images according to the input size needed for the VGG model
train_set_mnist = datasets.MNIST(root='./mnist_dataset', download=True, 
                                        train=True, transform=transforms.Compose([
                                            transforms.ToTensor(),
                                            transforms.Normalize((0.1307,), (0.3081,)),
                                            transforms.Resize((224, 224))
                                        ]))

test_set_mnist = datasets.MNIST(root='./mnist_dataset', download=False, 
                                        train=False, transform=transforms.Compose([
                                            transforms.ToTensor(),
                                            transforms.Normalize((0.1307,), (0.3081,)),
                                            transforms.Resize((224, 224))
                                        ]))

"""#### Setting the training and test loader"""

# Load and iterate over the elements of the datasets via the dataloader

# Create train loader
train_loader = torch.utils.data.DataLoader(dataset=train_set_mnist, batch_size=batch_size, shuffle=True)

# Create test loader
test_loader = torch.utils.data.DataLoader(dataset=test_set_mnist, batch_size=batch_size, shuffle=False)

"""#### Visualizing the images"""

# Visualize the test images
examples = enumerate(test_loader)
batch_idx, (example_data, example_targets) = next(examples)
fig = plt.figure()
for i in range(6):
  plt.subplot(2,3,i+1)
  plt.tight_layout()
  plt.imshow(example_data[i][0], cmap='gray', interpolation='none')
  plt.title("Ground Truth: {}".format(example_targets[i]))
  plt.xticks([])
  plt.yticks([])

# List to store the training and test accuracy and loss per epoch
training_accuracy = []
test_accuracy = []
training_loss = []
test_loss = []
best_accuracy = 0

# Store overall time taken to train and test during each epoch
time_taken_each_epoch = []

# Setting the path to store the model and time taken per epoch
save_path = "/content/drive/My Drive/Colab Notebooks/Animesh/state_dict_model_VGG16.pt"

writer = SummaryWriter('/content/drive/My Drive/Animesh/VGG_ResNet_MNIST')

"""VGG Model"""

class VGG16(nn.Module):
    def __init__(self):
        super(VGG16, self).__init__()
        self.conv1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3, padding=1)
        self.conv2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1)

        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)
        self.conv4 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)

        self.conv5 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1)
        self.conv6 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)
        self.conv7 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)

        self.conv8 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1)
        self.conv9 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)
        self.conv10 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)

        self.conv11 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)
        self.conv12 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)
        self.conv13 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)

        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)

        self.fc14 = nn.Linear(25088, 4096)
        self.fc15 = nn.Linear(4096, 4096)
        self.fc16 = nn.Linear(4096, 10)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        x = F.relu(self.conv2(x))
        x = self.maxpool(x)
        x = F.relu(self.conv3(x))
        x = F.relu(self.conv4(x))
        x = self.maxpool(x)
        x = F.relu(self.conv5(x))
        x = F.relu(self.conv6(x))
        x = F.relu(self.conv7(x))
        x = self.maxpool(x)
        x = F.relu(self.conv8(x))
        x = F.relu(self.conv9(x))
        x = F.relu(self.conv10(x))
        x = self.maxpool(x)
        x = F.relu(self.conv11(x))
        x = F.relu(self.conv12(x))
        x = F.relu(self.conv13(x))
        x = self.maxpool(x)
        x = x.reshape(x.shape[0], -1)
        x = F.relu(self.fc14(x))
        x = F.dropout(x, 0.5) #dropout was included to combat overfitting
        x = F.relu(self.fc15(x))
        x = F.dropout(x, 0.5)
        x = self.fc16(x)
        return x

"""#### Initializing the model & Defining the loss function and the Adam optimizer"""

# Initializing the model
network_VGG16 = VGG16()
network_VGG16.to(device)

# Setting the loss function and optimizer for the network
loss_function = nn.CrossEntropyLoss()
optimizer = optim.Adam(network_VGG16.parameters(), lr=learning_rate)

"""# VGG Model """

images, labels = next(iter(train_loader))
images = images.to(device)
grid = torchvision.utils.make_grid(images)

writer.add_image("images", grid)
writer.add_graph(network_VGG16, images)

# Commented out IPython magic to ensure Python compatibility.
# %tensorboard --logdir='/content/drive/My Drive/Animesh/VGG_ResNet_MNIST'

"""## Training and Testing the VGG model """

# Execute Training and testing for the number of epochs 
for epoch in range(epochs):
    epoch_start_time = time.time()
    
    ########### Training the VGG16 model ############
    network_VGG16.train()
    epoch_training_time = time.time()

    total_correct = 0  #Variable that calculates the total correct predictions done by the network
    running_loss = 0  #Variable to calculate the total loss of the dataset
    
    # calculating the accuacy and the loss of the network on the training loader dataset
    for batch in train_loader:
        training_images, training_labels = batch #Getting tensor of images and tensor of corresponding labels
        training_images, training_labels = training_images.to(device) , training_labels.to(device) #Passing the tensor to the GPU if available
        
        optimizer.zero_grad()#Set the gradient values to zero so that already present values are not added to the new batch
        
        predictions = network_VGG16(training_images) # Pass the batch to the network
        loss_train = loss_function(predictions, training_labels) # Calculating the loss
        
        loss_train.backward() # Calculate the gradients
        optimizer.step() # Update the weights
        
        running_loss += loss_train.item() #Add the loss calculated per batch

        #Calculate the element wise equality to measure the accuracy between the predictions and the labels
        predict_y = torch.max(predictions, dim=1)[1]
        total_correct += (predict_y == training_labels).sum().item()
        
    accuracy_train_epoch = total_correct / len(train_set_mnist)
    loss_train_epoch = running_loss / len(train_loader)
    training_accuracy.append(100.0 * accuracy_train_epoch)
    training_loss.append(loss_train_epoch)
        
    # Log training accuracy and loss per epoch to tensorboard
    writer.add_scalar('Train Accuracy', accuracy_train_epoch, epoch + 1)
    writer.add_scalar('Train Loss', loss_train_epoch, epoch + 1)

    ############ Testing the VGG16 model ############
    network_VGG16.eval()
    
    total_correct = 0
    running_loss = 0
    # calculating the accuacy and the loss of the network on the test loader dataset
    with torch.no_grad():
        for batch in test_loader:
            test_images, test_labels = batch #Getting tensor of images and tensor of corresponding labels
            test_images, test_labels = test_images.to(device), test_labels.to(device) #Passing the tensor to the GPU if available
            
            predictions = network_VGG16(test_images) # Pass the batch to the network
            loss_test = loss_function(predictions, test_labels) # Calculating the loss
            
            running_loss += loss_test.item() #Add the loss calculated per batch

            #Calculate the element wise equality to measure the accuracy between the predictions and the labels
            predict_y = torch.max(predictions, dim=1)[1]
            total_correct += (predict_y == test_labels).sum().item()
        
        accuracy_test_epoch = total_correct / len(test_set_mnist)
        loss_test_epoch = running_loss / len(test_loader)
        test_accuracy.append(100.0 * accuracy_test_epoch)
        test_loss.append(loss_test_epoch)
        
        if accuracy_test_epoch > best_accuracy:
            best_accuracy = accuracy_test_epoch
    
    # Log test accuracy and loss per epoch to tensorboard
    writer.add_scalar('Test Accuracy', accuracy_test_epoch, epoch + 1)
    writer.add_scalar('Test Loss', loss_test_epoch, epoch + 1)

    epoch_end_time = time.time()
    whole_time = epoch_end_time - epoch_start_time
    train_time = epoch_training_time - epoch_start_time
    time_taken_each_epoch.append(whole_time)
    
    print("Epoch [{}/{}], Training Accuracy:{:.2f}, Training Loss:{:.2f}, Test Accuracy:{:.2f}, Test Loss:{:.2f}".
             format(epoch + 1, epochs, accuracy_train_epoch, loss_train_epoch, accuracy_test_epoch, loss_test_epoch))

print('\n ******** Training and Testing Finished *******\n')

print(' || The total time taken: %.2f mins || The average time taken per epoch : %.2f mins' %
      (np.sum(time_taken_each_epoch)/60, np.sum(time_taken_each_epoch) / epochs / 60))

print('\n Best accuracy found %.2f' % best_accuracy)

# Specify a path
PATH = "/content/drive/My Drive/Animesh/state_dict_model_VGG16_MNIST.pt"

# Save
torch.save(network_VGG16.state_dict(), PATH)

"""#### Accuracy Plot"""

# Plotting the accuracy graph of training and test data of VGG16 model
epochs = range(1,21)
plt.plot(epochs, training_accuracy, 'g', label='Training Accuracy')
plt.plot(epochs, test_accuracy, 'b', label='Test Accuracy')
plt.title('VGG16 Training and Test accuracy per epoch on MNIST dataset')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

"""#### Loss Plot"""

# Plotting the loss graph of training and test data of VGG16 model
epochs = range(1,21)
plt.plot(epochs, training_loss, 'g', label='Training Loss')
plt.plot(epochs, test_loss, 'b', label='Test Loss')
plt.title('VGG16 Training and Test Loss per epoch on MNIST dataset')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

"""#### Showing the missclassified images  """

def get_predictions_on_testdata(model, test_loader):
    misclassified = []
    misclassified_pred = []
    misclassified_target = []

    total = 0
    correct = 0
    # put the model to evaluation mode
    model.eval()
    # turn off gradients

    with torch.no_grad():
        for data, target in test_loader:
            data, target = data.to(device), target.to(device)
            # do inferencing
            output = model(data)
            # get the predicted output
            pred = output.argmax(dim=1, keepdim=True)

            _, predicted = torch.max(output.data, 1)

            total += target.size(0)
            correct += (predicted == target).sum().item()
    

            # get the current misclassified in this batch
            list_misclassified = (pred.eq(target.view_as(pred)) == False)
            batch_misclassified = data[list_misclassified]
            batch_mis_pred = pred[list_misclassified]
            batch_mis_target = target.view_as(pred)[list_misclassified]

            misclassified.append(batch_misclassified)
            misclassified_pred.append(batch_mis_pred)
            misclassified_target.append(batch_mis_target)
    print('Accuracy:', (correct / total)*100)
    # group all the batches together
    misclassified = torch.cat(misclassified)
    misclassified_pred = torch.cat(misclassified_pred)
    misclassified_target = torch.cat(misclassified_target)

    return list(map(lambda x, y, z: (x, y, z), misclassified, misclassified_pred, misclassified_target))


# Print Some Labels for 
misclassified = get_predictions_on_testdata(network_VGG16, test_loader)

num_images = 10
fig = plt.figure(figsize=(10, 10))
for idx, (image, pred, target) in enumerate(random.choices(misclassified, k=num_images)):
    image, pred, target = image.cpu().numpy(), pred.cpu(), target.cpu()
    ax = fig.add_subplot(5, 5, idx+1)
    ax.axis('off')
    ax.set_title('target {}\npred {}'.format(target.item(), pred.item()), fontsize=13)
    ax.imshow(image.squeeze())
plt.tight_layout()
plt.show()


"""#### Storing the accuracy and loss logs in a file"""

# store the accuracy and loss in a dictionary
train_accuracy_dict = dict((key, val) for key, val in enumerate(training_accuracy, start=1))
test_accuracy_dict = dict((key, val) for key, val in enumerate(test_accuracy, start=1))
train_loss_dict = dict((key, val) for key, val in enumerate(training_loss, start=1))
test_loss_dict = dict((key, val) for key, val in enumerate(test_loss, start=1))

# Convert that dictionary into json format
json1 = json.dumps(train_accuracy_dict, indent=4)
json2 = json.dumps(test_accuracy_dict, indent=4)
json3 = json.dumps(train_loss_dict, indent=4)
json4 = json.dumps(test_loss_dict, indent=4)

#Store the files
with open('/content/drive/My Drive/Animesh/VGG16/VGG_MNIST_Results/train_accu_per_epoch.json', 'w') as json_file:
    json_file.write(json1)
with open('/content/drive/My Drive/Animesh/VGG16/VGG_MNIST_Results/test_accu_per_epoch.json', 'w') as json_file:
    json_file.write(json2)
with open('/content/drive/My Drive/Animesh/VGG16/VGG_MNIST_Results/train_loss_per_epoch.json', 'w') as json_file:
    json_file.write(json3)
with open('/content/drive/My Drive/Animesh/VGG16/VGG_MNIST_Results/test_loss_per_epoch.json', 'w') as json_file:
    json_file.write(json4)

"""#### Confusion Matrix """

################## Building Confusion Matrix ######################

from sklearn.metrics import confusion_matrix
import seaborn as sns
import pandas as pd

y_pred = []
y_true = []

# iterate over test data
for images, labels in test_loader:
        images, labels = images.to(device), labels.to(device)
        output = network_VGG16(images) # Feed Network

        output = (torch.max(torch.exp(output), 1)[1]).data.cpu().numpy()
        y_pred.extend(output) # Save Prediction
        
        labels = labels.data.cpu().numpy()
        y_true.extend(labels) # Save Truth

# constant for classes
classes = ('0','1','2','3','4','5','6','7','8','9')

# Build confusion matrix
cf_matrix = confusion_matrix(y_true, y_pred)
df_cm = pd.DataFrame(cf_matrix/np.sum(cf_matrix) *10, index = [i for i in classes],
                     columns = [i for i in classes])
plt.figure(figsize = (12,7))
sns.heatmap(df_cm, annot=True)







class ResidualBlock(nn.Module):
    def __init__(self,in_channels,out_channels,stride=1,kernel_size=3,padding=1,bias=False):
        super(ResidualBlock,self).__init__()
        self.cnn1 =nn.Sequential(
            nn.Conv2d(in_channels,out_channels,kernel_size,stride,padding,bias=False),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(True)
        )
        self.cnn2 = nn.Sequential(
            nn.Conv2d(out_channels,out_channels,kernel_size,1,padding,bias=False),
            nn.BatchNorm2d(out_channels)
        )
        if stride != 1 or in_channels != out_channels:
            self.shortcut = nn.Sequential(
                nn.Conv2d(in_channels,out_channels,kernel_size=1,stride=stride,bias=False),
                nn.BatchNorm2d(out_channels)
            )
        else:
            self.shortcut = nn.Sequential()
            
    def forward(self,x):
        residual = x
        x = self.cnn1(x)
        x = self.cnn2(x)
        x += self.shortcut(residual)
        x = nn.ReLU(True)(x)
        return x

class ResNet34(nn.Module):
    def __init__(self):
        super(ResNet34,self).__init__()
        
        self.block1 = nn.Sequential(
            nn.Conv2d(1,64,kernel_size=2,stride=2,padding=3,bias=False),
            nn.BatchNorm2d(64),
            nn.ReLU(True)
        )
        
        self.block2 = nn.Sequential(
            nn.MaxPool2d(1,1),
            ResidualBlock(64,64),
            ResidualBlock(64,64,2)
        )
        
        self.block3 = nn.Sequential(
            ResidualBlock(64,128),
            ResidualBlock(128,128,2)
        )
        
        self.block4 = nn.Sequential(
            ResidualBlock(128,256),
            ResidualBlock(256,256,2)
        )
        self.block5 = nn.Sequential(
            ResidualBlock(256,512),
            ResidualBlock(512,512,2)
        )
        
        self.avgpool = nn.AvgPool2d(2)

        self.fc = nn.Linear(512*4*4,10)
        
    def forward(self,x):
        x = self.block1(x)
        x = self.block2(x)
        x = self.block3(x)
        x = self.block4(x)
        x = self.block5(x)
        x = self.avgpool(x)
        x = x.view(x.size(0),-1)
        x = self.fc(x)
        return x

"""#### Initializing the model & Defining the loss function and the Adam optimizer"""

# Initializing the model
network_ResNet = ResNet34()
network_ResNet.to(device)

# Setting the loss function and optimizer for the network
loss_function = nn.CrossEntropyLoss()
optimizer = optim.Adam(network_ResNet.parameters(), lr=learning_rate)

"""#### Model's Summary """

from torchsummary import summary

# print the summary of the model
summary(network_ResNet, input_size=(1, 224, 224), batch_size=-1)

# List to store the training and test accuracy and loss per epoch
training_accuracy = []
test_accuracy = []
training_loss = []
test_loss = []
best_accuracy = 0.0

# Store overall time taken to train and test during each epoch
time_taken_each_epoch = []

# Setting the path to store the model and time taken per epoch
save_path = "./content/drive/My Drive/Colab Notebooks/Animesh/ResNet/MNIST"

# Setting the parameters 
batch_size = 64
epochs = 20
learning_rate = 0.0001
num_classes = 10

"""## Training and Testing the ResNet model """

# Execute Training and testing for the number of epochs 
for epoch in range(epochs):
    epoch_start_time = time.time()
    ########### Training the VGG16 model ############
    network_ResNet.train()
    epoch_training_time = time.time()

    total_correct = 0  #Variable that calculates the total correct predictions done by the network
    running_loss = 0  #Variable to calculate the total loss of the dataset
    
    # calculating the accuacy and the loss of the network on the training loader dataset
    for batch in train_loader:
        training_images, training_labels = batch #Getting tensor of images and tensor of corresponding labels
        training_images, training_labels = training_images.to(device) , training_labels.to(device) #Passing the tensor to the GPU if available
        
        optimizer.zero_grad()#Set the gradient values to zero so that already present values are not added to the new batch
        
        predictions = network_ResNet(training_images) # Pass the batch to the network
        loss_train = loss_function(predictions, training_labels) # Calculating the loss
        
        loss_train.backward() # Calculate the gradients
        optimizer.step() # Update the weights
        
        running_loss += loss_train.item() #Add the loss calculated per batch

        #Calculate the element wise equality to measure the accuracy between the predictions and the labels
        predict_y = torch.max(predictions, dim=1)[1]
        total_correct += (predict_y == training_labels).sum().item()
        
    accuracy_train_epoch = total_correct / len(train_set_mnist)
    loss_train_epoch = running_loss / len(train_loader)
    training_accuracy.append(100.0 * accuracy_train_epoch)
    training_loss.append(loss_train_epoch)
        
    # Log training accuracy and loss per epoch to tensorboard
    writer.add_scalar('Train Accuracy', accuracy_train_epoch, epoch + 1)
    writer.add_scalar('Train Loss', loss_train_epoch, epoch + 1)


    ############ Testing the VGG16 model ############
    network_ResNet.eval()
    
    total_correct = 0
    running_loss = 0
    # calculating the accuacy and the loss of the network on the test loader dataset
    with torch.no_grad():
        for batch in test_loader:
            test_images, test_labels = batch #Getting tensor of images and tensor of corresponding labels
            test_images, test_labels = test_images.to(device), test_labels.to(device) #Passing the tensor to the GPU if available
            
            predictions = network_ResNet(test_images) # Pass the batch to the network
            loss_test = loss_function(predictions, test_labels) # Calculating the loss
            
            running_loss += loss_test.item() #Add the loss calculated per batch

            #Calculate the element wise equality to measure the accuracy between the predictions and the labels
            predict_y = torch.max(predictions, dim=1)[1]
            total_correct += (predict_y == test_labels).sum().item()
        
        accuracy_test_epoch = total_correct / len(test_set_mnist)
        loss_test_epoch = running_loss / len(test_loader)
        test_accuracy.append(100.0 * accuracy_test_epoch)
        test_loss.append(loss_test_epoch)
        
        if accuracy_test_epoch > best_accuracy:
            best_accuracy = accuracy_test_epoch
    
    # Log test accuracy and loss per epoch to tensorboard
    writer.add_scalar('Test Accuracy', accuracy_test_epoch, epoch + 1)
    writer.add_scalar('Test Loss', loss_test_epoch, epoch + 1)
    
    
    epoch_end_time = time.time()
    whole_time = epoch_end_time - epoch_start_time
    train_time = epoch_training_time - epoch_start_time
    time_taken_each_epoch.append(whole_time)
    
    print("Epoch [{}/{}], Training Accuracy:{:.2f}, Training Loss:{:.2f}, Test Accuracy:{:.2f}, Test Loss:{:.2f}".
             format(epoch + 1, epochs, accuracy_train_epoch, loss_train_epoch, accuracy_test_epoch, loss_test_epoch))

print('\n ******** Training and Testing Finished *******\n')

print(' || The total time taken: %.2f mins || The average time taken per epoch : %.2f mins' %
      (np.sum(time_taken_each_epoch)/60, np.sum(time_taken_each_epoch) / epochs / 60))

print('\n Best accuracy found %.2f' % best_accuracy)

writer.close()

# Specify a path
PATH = "/content/drive/My Drive/Animesh/state_dict_model_ResNet34_MNIST.pt"

# Save the ResNet model
torch.save(network_ResNet.state_dict(), PATH)

"""#### Accuracy Plot """

# Plotting the accuracy graph of training and test data of ResNet model
epochs = range(1,21)
plt.plot(epochs, training_accuracy, 'g', label='Training Accuracy')
plt.plot(epochs, test_accuracy, 'b', label='Test Accuracy')
plt.title('ResNet Training and Test accuracy per epoch on MNIST dataset')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

"""#### Loss Plot """

# Plotting the loss graph of training and test data of ResNet model
epochs = range(1,21)
plt.plot(epochs, training_loss, 'g', label='Training Loss')
plt.plot(epochs, test_loss, 'b', label='Test Loss')
plt.title('ResNet Training and Test Loss per epoch on MNIST dataset')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

"""#### Showing the missclassified images """
def get_predictions_on_testdata(model, test_loader):
    misclassified = []
    misclassified_pred = []
    misclassified_target = []

    total = 0
    correct = 0
    # put the model to evaluation mode
    model.eval()
    # turn off gradients

    with torch.no_grad():
        for data, target in test_loader:
            data, target = data.to(device), target.to(device)
            # do inferencing
            output = model(data)
            # get the predicted output
            pred = output.argmax(dim=1, keepdim=True)

            _, predicted = torch.max(output.data, 1)

            total += target.size(0)
            correct += (predicted == target).sum().item()
    

            # get the current misclassified in this batch
            list_misclassified = (pred.eq(target.view_as(pred)) == False)
            batch_misclassified = data[list_misclassified]
            batch_mis_pred = pred[list_misclassified]
            batch_mis_target = target.view_as(pred)[list_misclassified]

            misclassified.append(batch_misclassified)
            misclassified_pred.append(batch_mis_pred)
            misclassified_target.append(batch_mis_target)
    print('Accuracy:', (correct / total)*100)
    # group all the batches together
    misclassified = torch.cat(misclassified)
    misclassified_pred = torch.cat(misclassified_pred)
    misclassified_target = torch.cat(misclassified_target)

    return list(map(lambda x, y, z: (x, y, z), misclassified, misclassified_pred, misclassified_target))


# Print Some Labels for 
misclassified = get_predictions_on_testdata(network_ResNet, test_loader)

num_images = 10
fig = plt.figure(figsize=(10, 10))
for idx, (image, pred, target) in enumerate(random.choices(misclassified, k=num_images)):
    image, pred, target = image.cpu().numpy(), pred.cpu(), target.cpu()
    ax = fig.add_subplot(5, 5, idx+1)
    ax.axis('off')
    ax.set_title('target {}\npred {}'.format(target.item(), pred.item()), fontsize=13)
    ax.imshow(image.squeeze())
plt.tight_layout()
plt.show()


"""#### Storing the accuracy and loss logs in a file """

# Store the accuracy and loss in a dictionary
train_accuracy_dict = dict((key, val) for key, val in enumerate(training_accuracy, start=1))
test_accuracy_dict = dict((key, val) for key, val in enumerate(test_accuracy, start=1))
train_loss_dict = dict((key, val) for key, val in enumerate(training_loss, start=1))
test_loss_dict = dict((key, val) for key, val in enumerate(test_loss, start=1))

# Convert that dictionary into json format
json1 = json.dumps(train_accuracy_dict, indent=4)
json2 = json.dumps(test_accuracy_dict, indent=4)
json3 = json.dumps(train_loss_dict, indent=4)
json4 = json.dumps(test_loss_dict, indent=4)

# Store the files
with open('/content/drive/My Drive/Animesh/ResNet/ResNet_MNIST_Results/train_accu_per_epoch.json', 'w') as json_file:
    json_file.write(json1)
with open('/content/drive/My Drive/Animesh/ResNet/ResNet_MNIST_Results/test_accu_per_epoch.json', 'w') as json_file:
    json_file.write(json2)
with open('/content/drive/My Drive/Animesh/ResNet/ResNet_MNIST_Results/train_loss_per_epoch.json', 'w') as json_file:
    json_file.write(json3)
with open('/content/drive/My Drive/Animesh/ResNet/ResNet_MNIST_Results/test_loss_per_epoch.json', 'w') as json_file:
    json_file.write(json4)

"""#### Confusion Matrix """

################### Building Confusion Matrix #####################

from sklearn.metrics import confusion_matrix
import seaborn as sns
import pandas as pd

y_pred = []
y_true = []

# iterate over test data
for images, labels in test_loader:
        images, labels = images.to(device), labels.to(device)
        output = network_ResNet(images) # Feed Network

        output = (torch.max(torch.exp(output), 1)[1]).data.cpu().numpy()
        y_pred.extend(output) # Save Prediction
        
        labels = labels.data.cpu().numpy()
        y_true.extend(labels) # Save Truth

# constant for classes
classes = ('0','1','2','3','4','5','6','7','8','9')

# Build confusion matrix
cf_matrix = confusion_matrix(y_true, y_pred)
df_cm = pd.DataFrame(cf_matrix/np.sum(cf_matrix) *10, index = [i for i in classes],
                     columns = [i for i in classes])
plt.figure(figsize = (12,7))
sns.heatmap(df_cm, annot=True)



# Commented out IPython magic to ensure Python compatibility.
# %tensorboard --logdir='/content/drive/My Drive/Animesh/VGG_ResNet_MNIST'

#tensorboard --logdir=runs/ --host localhost --port 8089