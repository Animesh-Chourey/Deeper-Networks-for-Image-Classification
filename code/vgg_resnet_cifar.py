# -*- coding: utf-8 -*-
"""VGG_ResNet_CIFAR.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19_Ozkvc63zyjvXTkeNsCqRUiDyBzDuiE

### Mounting the drive
"""

from google.colab import drive
drive.mount('/content/drive/')

!nvidia-smi

"""### Importing Packages """

# Commented out IPython magic to ensure Python compatibility.
import torch
import torchvision
import torchvision.datasets as datasets
from torchvision import transforms
from torch.utils.data import random_split
from torch import nn
import torch.nn.functional as F
import torch.optim as optim
import matplotlib.pyplot as plt
import time
import numpy as np
import os
import random
from torch.utils.tensorboard import SummaryWriter
from torchvision.datasets import CIFAR10
import itertools

# Load the TensorBoard notebook extension
%load_ext tensorboard

"""# VGG Model"""

class VGG16(nn.Module):
    def __init__(self):
        super(VGG16, self).__init__()
        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1)
        self.conv2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1)

        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)
        self.conv4 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)

        self.conv5 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1)
        self.conv6 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)
        self.conv7 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)

        self.conv8 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1)
        self.conv9 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)
        self.conv10 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)

        self.conv11 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)
        self.conv12 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)
        self.conv13 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)

        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)

        self.fc14 = nn.Linear(25088, 4096)
        self.fc15 = nn.Linear(4096, 4096)
        self.fc16 = nn.Linear(4096, 10)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        x = F.relu(self.conv2(x))
        x = self.maxpool(x)
        x = F.relu(self.conv3(x))
        x = F.relu(self.conv4(x))
        x = self.maxpool(x)
        x = F.relu(self.conv5(x))
        x = F.relu(self.conv6(x))
        x = F.relu(self.conv7(x))
        x = self.maxpool(x)
        x = F.relu(self.conv8(x))
        x = F.relu(self.conv9(x))
        x = F.relu(self.conv10(x))
        x = self.maxpool(x)
        x = F.relu(self.conv11(x))
        x = F.relu(self.conv12(x))
        x = F.relu(self.conv13(x))
        x = self.maxpool(x)
        x = x.reshape(x.shape[0], -1)
        x = F.relu(self.fc14(x))
        x = F.dropout(x, 0.5) #dropout was included to combat overfitting
        x = F.relu(self.fc15(x))
        x = F.dropout(x, 0.5)
        x = self.fc16(x)
        return x

"""#### Parameters and device """

# Setting the device to GPU if available
device = 'cuda' if torch.cuda.is_available() else 'cpu'

# Setting the parameters 
batch_size = 32
epochs = 20
learning_rate = 0.0001
num_classes = 10

"""#### Loading the dataset"""

torch.manual_seed(1)


train_transform = transforms.Compose([
                  transforms.ToTensor(),
                  transforms.Normalize((0.491, 0.482, 0.446), (0.247, 0.243, 0.261)),
                  transforms.Resize((224, 224))])

test_transform = transforms.Compose([
                 transforms.ToTensor(),
                 transforms.Normalize((0.491, 0.482, 0.446), (0.247, 0.243, 0.261)),
                 transforms.Resize((224, 224))])

train_set_cifar10 = CIFAR10(root='./cifar10_dataset', train=True, download=True, transform=train_transform) # Download the data and store it in cw3_mnist folder
test_set_cifar10 = CIFAR10(root='./cifar10_dataset', train=False, download=True, transform=test_transform) # Download test data and store it in cw3_mnist folder

"""#### Setting the training and test loader"""

# Load and iterate over the elements of the datasets via the dataloader

# Create train loader
train_loader = torch.utils.data.DataLoader(dataset=train_set_cifar10, batch_size=batch_size, shuffle=True)

# Create test loader
test_loader = torch.utils.data.DataLoader(dataset=test_set_cifar10, batch_size=batch_size, shuffle=False)

"""#### Visualizing the images"""

# Visualize the test images
examples = enumerate(test_loader)
batch_idx, (example_data, example_targets) = next(examples)
fig = plt.figure()
for i in range(6):
  plt.subplot(2,3,i+1)
  plt.tight_layout()
  plt.imshow(example_data[i][0], cmap='gray', interpolation='none')
  plt.title("Ground Truth: {}".format(example_targets[i]))
  plt.xticks([])
  plt.yticks([])

"""#### Initializing the model & Defining the loss function and the Adam optimizer"""

# Initializing the model
network_VGG16 = VGG16()
network_VGG16.to(device)

# Setting the loss function and optimizer for the network
loss_function = nn.CrossEntropyLoss()
optimizer = optim.Adam(network_VGG16.parameters(), lr=learning_rate)

# List to store the training and test accuracy and loss per epoch
training_accuracy = []
test_accuracy = []
training_loss = []
test_loss = []
best_accuracy = 0.0

# Store overall time taken to train and test during each epoch
time_taken_each_epoch = []

# Setting the path to store the model and time taken per epoch
save_path = "./content/drive/My Drive/Colab Notebooks/Animesh/VGG16/CIFAR"

writer = SummaryWriter()

"""## Training and Testing the GoogLeNet model """

# Execute Training and testing for the number of epochs 
for epoch in range(epochs):
    epoch_start_time = time.time()
    
    ############# Training the VGG16 model   ##############
    network_VGG16.train()
    epoch_training_time = time.time()

    total_correct = 0  #Variable that calculates the total correct predictions done by the network
    running_loss = 0.0  #Variable to calculate the total loss of the dataset
    
    # calculating the accuacy and the loss of the network on the training loader dataset
    for batch in train_loader:
        training_images, training_labels = batch #Getting tensor of images and tensor of corresponding labels
        training_images, training_labels = training_images.to(device) , training_labels.to(device) #Passing the tensor to the GPU if available

        optimizer.zero_grad()# Set the gradient values to zero so that already present values are not added to the new batch
        
        predictions = network_VGG16(training_images) # Pass the batch to the network
        loss_train = loss_function(predictions, training_labels) # Calculating the loss
        
        loss_train.backward() # Calculate the gradients
        optimizer.step() # Update the weights
        
        running_loss += loss_train.item() #Add the loss calculated per batch

        #Calculate the element wise equality to measure the accuracy between the predictions and the labels
        predict_y = torch.max(predictions, dim=1)[1]
        total_correct += (predict_y == training_labels).sum().item()
        
    accuracy_train_epoch = total_correct / len(train_set_cifar10)
    loss_train_epoch = running_loss / len(train_loader)
    training_accuracy.append(100.0 * accuracy_train_epoch)
    training_loss.append(loss_train_epoch)
        
    # Log training accuracy and loss per epoch to tensorboard
    writer.add_scalar('Train Accuracy', accuracy_train_epoch, epoch + 1)
    writer.add_scalar('Train Loss', loss_train_epoch, epoch + 1)

    ############# Testing the VGG16 model  ##############
    network_VGG16.eval()
    
    total_correct = 0
    running_loss = 0.0
    with torch.no_grad():
        # calculating the accuacy and the loss of the network on the test loader dataset
        for batch in test_loader:
            test_images, test_labels = batch #Getting tensor of images and tensor of corresponding labels
            test_images, test_labels = test_images.to(device), test_labels.to(device) #Passing the tensor to the GPU if available
            
            predictions = network_VGG16(test_images) # Pass the batch to the network
            loss_test = loss_function(predictions, test_labels) # Calculating the loss
            
            running_loss += loss_test.item() #Add the loss calculated per batch

            #Calculate the element wise equality to measure the accuracy between the predictions and the labels
            predict_y = torch.max(predictions, dim=1)[1]
            total_correct += (predict_y == test_labels).sum().item()
        
        accuracy_test_epoch = total_correct / len(test_set_cifar10)
        loss_test_epoch = running_loss / len(test_loader)
        test_accuracy.append(100.0 * accuracy_test_epoch)
        test_loss.append(loss_test_epoch)
        
        if accuracy_test_epoch > best_accuracy:
            best_accuracy = accuracy_test_epoch
    
        # Log test accuracy and loss per epoch to tensorboard
        writer.add_scalar('Test Accuracy', accuracy_test_epoch, epoch + 1)
        writer.add_scalar('Test Loss', loss_test_epoch, epoch + 1)

    epoch_end_time = time.time()
    whole_time = epoch_end_time - epoch_start_time
    train_time = epoch_training_time - epoch_start_time
    time_taken_each_epoch.append(whole_time)
    
    print("Epoch [{}/{}], Training Accuracy:{:.2f}, Training Loss:{:.2f}, Test Accuracy:{:.2f}, Test Loss:{:.2f}".
             format(epoch + 1, epochs, accuracy_train_epoch, loss_train_epoch, accuracy_test_epoch, loss_test_epoch))

print('***Training Finished***')

print(' The total time cost is: %.2fmin || The average time per epoch is: %.2fmin' %
      (np.sum(time_taken_each_epoch)/60, np.sum(time_taken_each_epoch) / epochs / 60))

print('Best accuracy found %.2f' % best_accuracy)

# Specify a path
PATH = "/content/drive/My Drive/Colab Notebooks/Animesh/state_dict_model_VGG16_CIFAR.pt"

# Save
torch.save(network_VGG16.state_dict(), PATH)

"""#### Accuracy Plot"""

# Plotting the accuracy graph of training and test data of VGG16 model
epochs = range(1,21)
plt.plot(epochs, training_accuracy, 'g', label='Training Accuracy')
plt.plot(epochs, test_accuracy, 'b', label='Test Accuracy')
plt.title('VGG16 Training and Test accuracy per epoch on CIFAR dataset')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

"""#### Loss Plot"""

# Plotting the loss graph of training and test data of VGG16 model
epochs = range(1,21)
plt.plot(epochs, training_loss, 'g', label='Training Loss')
plt.plot(epochs, test_loss, 'b', label='Test Loss')
plt.title('VGG16 Training and Test Loss per epoch on CIFAR dataset')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()


"""#### Storing the accuracy and loss logs in a file"""

import json
# Store the accuracy and loss in a dictionary
train_accuracy_dict = dict((key, val) for key, val in enumerate(training_accuracy, start=1))
test_accuracy_dict = dict((key, val) for key, val in enumerate(test_accuracy, start=1))
train_loss_dict = dict((key, val) for key, val in enumerate(training_loss, start=1))
test_loss_dict = dict((key, val) for key, val in enumerate(test_loss, start=1))

# Convert that dictionary into json format
json1 = json.dumps(train_accuracy_dict, indent=4)
json2 = json.dumps(test_accuracy_dict, indent=4)
json3 = json.dumps(train_loss_dict, indent=4)
json4 = json.dumps(test_loss_dict, indent=4)

# Store the files
with open('/content/drive/My Drive/Colab Notebooks/Animesh/VGG16/VGG_CIFAR_Results/train_accu_per_epoch.json', 'w') as json_file:
    json_file.write(json1)
with open('/content/drive/My Drive/Colab Notebooks/Animesh/VGG16/VGG_CIFAR_Results/test_accu_per_epoch.json', 'w') as json_file:
    json_file.write(json2)
with open('/content/drive/My Drive/Colab Notebooks/Animesh/VGG16/VGG_CIFAR_Results/train_loss_per_epoch.json', 'w') as json_file:
    json_file.write(json3)
with open('/content/drive/My Drive/Colab Notebooks/Animesh/VGG16/VGG_CIFAR_Results/test_loss_per_epoch.json', 'w') as json_file:
    json_file.write(json4)

"""#### Confusion Matrix """

########## Building Confusion Matrix #####################

from sklearn.metrics import confusion_matrix
import seaborn as sns
import pandas as pd

y_pred = []
y_true = []

# iterate over test data
for images, labels in test_loader:
        images, labels = images.to(device), labels.to(device)
        output = network_VGG16(images) # Feed Network

        output = (torch.max(torch.exp(output), 1)[1]).data.cpu().numpy()
        y_pred.extend(output) # Save Prediction
        
        labels = labels.data.cpu().numpy()
        y_true.extend(labels) # Save Truth

# constant for classes
classes = ('airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck')

# Build confusion matrix
cf_matrix = confusion_matrix(y_true, y_pred)
df_cm = pd.DataFrame(cf_matrix/np.sum(cf_matrix) *10, index = [i for i in classes],
                     columns = [i for i in classes])
plt.figure(figsize = (12,7))
sns.heatmap(df_cm, annot=True)



"""# ResNet Model """

class ResidualBlock(nn.Module):
    def __init__(self,in_channels,out_channels,stride=1,kernel_size=3,padding=1,bias=False):
        super(ResidualBlock,self).__init__()
        self.cnn1 =nn.Sequential(
            nn.Conv2d(in_channels,out_channels,kernel_size,stride,padding,bias=False),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(True)
        )
        self.cnn2 = nn.Sequential(
            nn.Conv2d(out_channels,out_channels,kernel_size,1,padding,bias=False),
            nn.BatchNorm2d(out_channels)
        )
        if stride != 1 or in_channels != out_channels:
            self.shortcut = nn.Sequential(
                nn.Conv2d(in_channels,out_channels,kernel_size=1,stride=stride,bias=False),
                nn.BatchNorm2d(out_channels)
            )
        else:
            self.shortcut = nn.Sequential()
            
    def forward(self,x):
        residual = x
        x = self.cnn1(x)
        x = self.cnn2(x)
        x += self.shortcut(residual)
        x = nn.ReLU(True)(x)
        return x

class ResNet34(nn.Module):
    def __init__(self):
        super(ResNet34,self).__init__()
        
        self.block1 = nn.Sequential(
            nn.Conv2d(3,64,kernel_size=2,stride=2,padding=3,bias=False),
            nn.BatchNorm2d(64),
            nn.ReLU(True)
        )
        
        self.block2 = nn.Sequential(
            nn.MaxPool2d(1,1),
            ResidualBlock(64,64),
            ResidualBlock(64,64,2)
        )
        
        self.block3 = nn.Sequential(
            ResidualBlock(64,128),
            ResidualBlock(128,128,2)
        )
        
        self.block4 = nn.Sequential(
            ResidualBlock(128,256),
            ResidualBlock(256,256,2)
        )
        self.block5 = nn.Sequential(
            ResidualBlock(256,512),
            ResidualBlock(512,512,2)
        )
        
        self.avgpool = nn.AvgPool2d(2)

        self.fc = nn.Linear(512*4*4,10)
        
    def forward(self,x):
        x = self.block1(x)
        x = self.block2(x)
        x = self.block3(x)
        x = self.block4(x)
        x = self.block5(x)
        x = self.avgpool(x)
        x = x.view(x.size(0),-1)
        x = self.fc(x)
        return x

"""## Parameters and device """

# Setting the device to GPU if available
device = 'cuda' if torch.cuda.is_available() else 'cpu'

# Setting the parameters 
batch_size = 32
epochs = 20
learning_rate = 0.0001
num_classes = 10

"""## Initializing the model & Defining the loss function and the Adam optimizer """

# Initializing the model
network_ResNet = ResNet34()
network_ResNet.to(device)

# Setting the loss function and optimizer for the network
loss_function = nn.CrossEntropyLoss()
optimizer = optim.Adam(network_ResNet.parameters(), lr=learning_rate)

"""### Model's Summary """

from torchsummary import summary

# print the summary of the model
summary(network_ResNet, input_size=(3, 224, 224), batch_size=-1)

# List to store the training and test accuracy and loss per epoch
training_accuracy = []
test_accuracy = []
training_loss = []
test_loss = []
best_accuracy = 0.0

# Store overall time taken to train and test during each epoch
time_taken_each_epoch = []

# Setting the path to store the model and time taken per epoch
save_path = "./content/drive/My Drive/Colab Notebooks/Animesh/ResNet/CIFAR"

"""## Training and Testing the ResNet model """

# Execute Training and testing for the number of epochs 
for epoch in range(epochs):
    epoch_start_time = time.time()
    ########### Training the VGG16 model ############
    network_ResNet.train()
    epoch_training_time = time.time()

    total_correct = 0  #Variable that calculates the total correct predictions done by the network
    running_loss = 0  #Variable to calculate the total loss of the dataset
    
    # calculating the accuacy and the loss of the network on the training loader dataset
    for batch in train_loader:
        training_images, training_labels = batch #Getting tensor of images and tensor of corresponding labels
        training_images, training_labels = training_images.to(device) , training_labels.to(device) #Passing the tensor to the GPU if available
        
        optimizer.zero_grad()#Set the gradient values to zero so that already present values are not added to the new batch
        
        predictions = network_ResNet(training_images) # Pass the batch to the network
        loss_train = loss_function(predictions, training_labels) # Calculating the loss
        
        loss_train.backward() # Calculate the gradients
        optimizer.step() # Update the weights
        
        running_loss += loss_train.item() #Add the loss calculated per batch

        #Calculate the element wise equality to measure the accuracy between the predictions and the labels
        predict_y = torch.max(predictions, dim=1)[1]
        total_correct += (predict_y == training_labels).sum().item()
        
    accuracy_train_epoch = total_correct / len(train_set_cifar10)
    loss_train_epoch = running_loss / len(train_loader)
    training_accuracy.append(100.0 * accuracy_train_epoch)
    training_loss.append(loss_train_epoch)
        
    # Log training accuracy and loss per epoch to tensorboard
    writer.add_scalar('Train Accuracy', accuracy_train_epoch, epoch + 1)
    writer.add_scalar('Train Loss', loss_train_epoch, epoch + 1)


    ############ Testing the VGG16 model ############
    network_ResNet.eval()
    
    total_correct = 0
    running_loss = 0
    # calculating the accuacy and the loss of the network on the test loader dataset
    with torch.no_grad():
        for batch in test_loader:
            test_images, test_labels = batch #Getting tensor of images and tensor of corresponding labels
            test_images, test_labels = test_images.to(device), test_labels.to(device) #Passing the tensor to the GPU if available
            
            predictions = network_ResNet(test_images) # Pass the batch to the network
            loss_test = loss_function(predictions, test_labels) # Calculating the loss
            
            running_loss += loss_test.item() #Add the loss calculated per batch

            #Calculate the element wise equality to measure the accuracy between the predictions and the labels
            predict_y = torch.max(predictions, dim=1)[1]
            total_correct += (predict_y == test_labels).sum().item()
        
        accuracy_test_epoch = total_correct / len(test_set_cifar10)
        loss_test_epoch = running_loss / len(test_loader)
        test_accuracy.append(100.0 * accuracy_test_epoch)
        test_loss.append(loss_test_epoch)
        
        if accuracy_test_epoch > best_accuracy:
            best_accuracy = accuracy_test_epoch
    
    # Log test accuracy and loss per epoch to tensorboard
    writer.add_scalar('Test Accuracy', accuracy_test_epoch, epoch + 1)
    writer.add_scalar('Test Loss', loss_test_epoch, epoch + 1)
    
    
    epoch_end_time = time.time()
    whole_time = epoch_end_time - epoch_start_time
    train_time = epoch_training_time - epoch_start_time
    time_taken_each_epoch.append(whole_time)
    
    print("Epoch [{}/{}], Training Accuracy:{:.2f}, Training Loss:{:.2f}, Test Accuracy:{:.2f}, Test Loss:{:.2f}".
             format(epoch + 1, epochs, accuracy_train_epoch, loss_train_epoch, accuracy_test_epoch, loss_test_epoch))

print('\n ******** Training and Testing Finished *******\n')

print(' || The total time taken: %.2f mins || The average time taken per epoch : %.2f mins' %
      (np.sum(time_taken_each_epoch)/60, np.sum(time_taken_each_epoch) / epochs / 60))

print('\n Best accuracy found %.2f' % best_accuracy)

writer.close()

# Specify a path
PATH = "/content/drive/My Drive/Colab Notebooks/Animesh/state_dict_model_ResNet34_CIFAR.pt"

# Save
torch.save(network_ResNet.state_dict(), PATH)

"""## Accuracy Plot """

# Plotting the accuracy graph of training and test data of ResNet model
epochs = range(1,21)
plt.plot(epochs, training_accuracy, 'g', label='Training Accuracy')
plt.plot(epochs, test_accuracy, 'b', label='Test Accuracy')
plt.title('ResNet Training and Test accuracy per epoch on CIFAR dataset')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

"""## Loss Plot """

# Plotting the loss graph of training and test data of ResNet model
epochs = range(1,21)
plt.plot(epochs, training_loss, 'g', label='Training Loss')
plt.plot(epochs, test_loss, 'b', label='Test Loss')
plt.title('ResNet Training and Test Loss per epoch on CIFAR dataset')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()


"""## Storing the accuracy and loss logs in a file """

import json
# Store the accuracy and loss in a dictionary
train_accuracy_dict = dict((key, val) for key, val in enumerate(training_accuracy, start=1))
test_accuracy_dict = dict((key, val) for key, val in enumerate(test_accuracy, start=1))
train_loss_dict = dict((key, val) for key, val in enumerate(training_loss, start=1))
test_loss_dict = dict((key, val) for key, val in enumerate(test_loss, start=1))

# Convert that dictionary into json format
json1 = json.dumps(train_accuracy_dict, indent=4)
json2 = json.dumps(test_accuracy_dict, indent=4)
json3 = json.dumps(train_loss_dict, indent=4)
json4 = json.dumps(test_loss_dict, indent=4)

# Store the files
with open('/content/drive/My Drive/Colab Notebooks/Animesh/ResNet/ResNet_CIFAR_Results/train_accu_per_epoch.json', 'w') as json_file:
    json_file.write(json1)
with open('/content/drive/My Drive/Colab Notebooks/Animesh/ResNet/ResNet_CIFAR_Results/test_accu_per_epoch.json', 'w') as json_file:
    json_file.write(json2)
with open('/content/drive/My Drive/Colab Notebooks/Animesh/ResNet/ResNet_CIFAR_Results/train_loss_per_epoch.json', 'w') as json_file:
    json_file.write(json3)
with open('/content/drive/My Drive/Colab Notebooks/Animesh/ResNet/ResNet_CIFAR_Results/test_loss_per_epoch.json', 'w') as json_file:
    json_file.write(json4)

"""## Confusion Matrix """

################### Building Confusion Matrix #####################

from sklearn.metrics import confusion_matrix
import seaborn as sns
import pandas as pd

y_pred = []
y_true = []

# iterate over test data
for images, labels in test_loader:
        images, labels = images.to(device), labels.to(device)
        output = network_ResNet(images) # Feed Network

        output = (torch.max(torch.exp(output), 1)[1]).data.cpu().numpy()
        y_pred.extend(output) # Save Prediction
        
        labels = labels.data.cpu().numpy()
        y_true.extend(labels) # Save Truth

# constant for classes
classes = ('airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck')

# Build confusion matrix
cf_matrix = confusion_matrix(y_true, y_pred)
df_cm = pd.DataFrame(cf_matrix/np.sum(cf_matrix) *10, index = [i for i in classes],
                     columns = [i for i in classes])
plt.figure(figsize = (12,7))
sns.heatmap(df_cm, annot=True)



tensorboard --logdir=runs/ --host localhost --port 8090